{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6488923,"sourceType":"datasetVersion","datasetId":3749709}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install --upgrade transformers datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T10:35:21.498720Z","iopub.execute_input":"2025-04-18T10:35:21.498897Z","iopub.status.idle":"2025-04-18T10:35:34.365340Z","shell.execute_reply.started":"2025-04-18T10:35:21.498880Z","shell.execute_reply":"2025-04-18T10:35:34.364532Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nCollecting transformers\n  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec, transformers\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.51.1\n    Uninstalling transformers-4.51.1:\n      Successfully uninstalled transformers-4.51.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.8.4.1 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.3.3.83 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.9.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.3.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.8.93 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.8.93 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fsspec-2024.12.0 transformers-4.51.3\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Semantic Search on Review Dataset - Kaggle Ready Notebook\n\nimport pandas as pd\nimport re\nimport torch\nfrom sentence_transformers import SentenceTransformer, util\nimport os\nimport shutil","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T10:35:34.367004Z","iopub.execute_input":"2025-04-18T10:35:34.367244Z","iopub.status.idle":"2025-04-18T10:35:59.899434Z","shell.execute_reply.started":"2025-04-18T10:35:34.367224Z","shell.execute_reply":"2025-04-18T10:35:59.898678Z"}},"outputs":[{"name":"stderr","text":"2025-04-18 10:35:46.477765: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1744972546.666897      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1744972546.723468      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from IPython.display import FileLink, display","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T10:35:59.900415Z","iopub.execute_input":"2025-04-18T10:35:59.901024Z","iopub.status.idle":"2025-04-18T10:35:59.904663Z","shell.execute_reply.started":"2025-04-18T10:35:59.900998Z","shell.execute_reply":"2025-04-18T10:35:59.904024Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Load dataset\nfile_path = \"/kaggle/input/fake-reviews-dataset/fake reviews dataset.csv\"  # Replace with your dataset name on Kaggle\n\ndef load_and_clean_data(file_path):\n    df = pd.read_csv(file_path)\n    df.columns = [col.strip().lower() for col in df.columns]\n    \n    # Check required columns\n    if 'text_' not in df.columns:\n        raise ValueError(\"Column 'text_' is required in the dataset.\")\n\n    df = df[df['text_'].notnull()]\n    df['text'] = df['text_'].apply(preprocess_text)\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T10:35:59.905498Z","iopub.execute_input":"2025-04-18T10:35:59.905762Z","iopub.status.idle":"2025-04-18T10:36:00.158133Z","shell.execute_reply.started":"2025-04-18T10:35:59.905739Z","shell.execute_reply":"2025-04-18T10:36:00.157410Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def preprocess_text(text):\n    if isinstance(text, str):\n        text = text.lower()\n        text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n        text = re.sub(r'\\s+', ' ', text).strip()\n        return text\n    return \"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T10:36:00.158880Z","iopub.execute_input":"2025-04-18T10:36:00.159138Z","iopub.status.idle":"2025-04-18T10:36:00.171920Z","shell.execute_reply.started":"2025-04-18T10:36:00.159098Z","shell.execute_reply":"2025-04-18T10:36:00.171168Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Label conversion\ndef assign_labels(df):\n    if 'label' not in df.columns or 'text_' not in df.columns:\n        raise ValueError(\"Dataset must contain 'text_' and 'label' columns. Found: {}\".format(df.columns.tolist()))\n\n    label_mapping = {'OR': 0, 'CG': 1}\n    df = df[df['text_'].notnull()]\n    df['label'] = df['label'].map(label_mapping)\n\n    if df['label'].isnull().any():\n        raise ValueError(\"Label conversion failed — check for invalid labels in your data.\")\n\n    df['text'] = df['text_'].apply(preprocess_text)\n    return df[['label', 'text']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T10:36:00.172764Z","iopub.execute_input":"2025-04-18T10:36:00.173423Z","iopub.status.idle":"2025-04-18T10:36:00.185645Z","shell.execute_reply.started":"2025-04-18T10:36:00.173399Z","shell.execute_reply":"2025-04-18T10:36:00.184867Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Semantic Search Class\nimport os\nimport torch\nimport shutil\nimport pickle\nfrom sentence_transformers import SentenceTransformer, util\nfrom IPython.display import FileLink, display\n\nclass SemanticSearchEngine:\n    def __init__(self, texts, model_name='all-MiniLM-L6-v2'):\n        print(\"Loading SentenceTransformer model...\")\n        self.model = SentenceTransformer(model_name)\n        print(\"Encoding all reviews...\")\n        self.texts = texts\n        self.embeddings = self.model.encode(texts, convert_to_tensor=True)\n        print(\"✅ Embeddings ready!\")\n\n        # Save model\n        os.makedirs(\"saved_model\", exist_ok=True)\n        self.model.save(\"saved_model\")\n\n        # Save embeddings and texts\n        #os.makedirs(\"semantic_search_model\", exist_ok=True)\n        torch.save(self.embeddings, \"saved_model/embeddings.pt\")\n        with open(\"saved_model/texts.pkl\", \"wb\") as f:\n            pickle.dump(self.texts, f)\n\n        # Zip model and semantic search folder\n        shutil.make_archive(\"saved_model\", 'zip', \"saved_model\")\n        #shutil.make_archive(\"semantic_search_model\", 'zip', \"semantic_search_model\")\n\n        # Create download links\n        display(FileLink(\"saved_model.zip\"))\n        #display(FileLink(\"semantic_search_model.zip\"))\n\n    def search(self, query, top_k=5):\n        query_embedding = self.model.encode(query, convert_to_tensor=True)\n        cos_scores = util.pytorch_cos_sim(query_embedding, self.embeddings)[0]\n        top_results = torch.topk(cos_scores, k=top_k)\n\n        print(f\"\\nTop {top_k} results for query: \\\"{query}\\\"\")\n        for score, idx in zip(top_results[0], top_results[1]):\n            print(f\"Score: {score:.4f} - Review: {self.texts[idx]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T10:36:00.187200Z","iopub.execute_input":"2025-04-18T10:36:00.187414Z","iopub.status.idle":"2025-04-18T10:36:00.200605Z","shell.execute_reply.started":"2025-04-18T10:36:00.187389Z","shell.execute_reply":"2025-04-18T10:36:00.199885Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Run Semantic Search\nif __name__ == \"__main__\":\n    df = load_and_clean_data(file_path)\n    search_engine = SemanticSearchEngine(df['text'].tolist())\n\n    # Example queries\n    search_engine.search(\"good quality and reliable product\")\n    search_engine.search(\"scam or fake review packaging damaged\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T10:36:00.201297Z","iopub.execute_input":"2025-04-18T10:36:00.201587Z","iopub.status.idle":"2025-04-18T10:36:36.867824Z","shell.execute_reply.started":"2025-04-18T10:36:00.201548Z","shell.execute_reply":"2025-04-18T10:36:36.867089Z"}},"outputs":[{"name":"stdout","text":"Loading SentenceTransformer model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5aa70e75e173486592db9073f1d90681"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa78ca83a4044b4ebb96ad3ad227b6d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67d5caf7214d4417ae556c3f891f4339"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f938819c4a8a429496f8911626e90809"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7f251d56c1e46a8a4f5a1e212aa7666"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbbec619ab994ae988e9cd75a4704373"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2e4017191714b98aa59d2658f3e3d3a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78b096212dd94de4a73697a579fb64b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"403935b4cef9421e91ec080f1108b56f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2db0a4214b0445bb91a0dcc1c62b545f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26bbc4ce6c8749deb856692f4a5b4cce"}},"metadata":{}},{"name":"stdout","text":"Encoding all reviews...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1264 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca69f9ccf25a479ba7f5c37f6be799e8"}},"metadata":{}},{"name":"stdout","text":"✅ Embeddings ready!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/saved_model.zip","text/html":"<a href='saved_model.zip' target='_blank'>saved_model.zip</a><br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"566acdf4285f4ed39e6fa682e73e3528"}},"metadata":{}},{"name":"stdout","text":"\nTop 5 results for query: \"good quality and reliable product\"\nScore: 0.7466 - Review: great product it is highly reliable durable and affordable prices touched my heart i would recommend this product to a friend\nScore: 0.7350 - Review: good quality and nice price especially for the price very good quality\nScore: 0.7247 - Review: product is good and great quality the only problem is that it comes with a small piece of cardboard if you want to\nScore: 0.7232 - Review: great quality and function very well made\nScore: 0.7037 - Review: a great product and excellent customer service great product for the moneythis is a pretty good\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb10c93918e74c56b0493c2cf49613d0"}},"metadata":{}},{"name":"stdout","text":"\nTop 5 results for query: \"scam or fake review packaging damaged\"\nScore: 0.5745 - Review: i wrote a review and here it is i received this product at a discounted rate in exchange for my honest and unbiased review the product was packaged in a\nScore: 0.5620 - Review: package came beat up and retaped but actual product was fine\nScore: 0.5474 - Review: i bought this directly from costco the shipping was quick and it arrived intact i was surprised to find that the packaging was plastic not the clear plastic plastic of the cardboard box the packaging was well packaged and in good condition the size was perfect\nScore: 0.5318 - Review: ive had the bluesmart for a couple of years now and im still happy with the product the other two have had problems the first one is the plastic part the second one is the plastic part its a little thin on the bottom but i dont feel its going to get damaged i did get a free shipping label on the first one and the second one was great the first one was defective and the second one is a good product the second one is a little flimsy but im glad i got it for free i just wish the first one had a more sturdy plastic part so i could try it out the only negative i can say is the shipping label does not cover the front of the box ive had it for a while now and i have no problems with the shipping label i will update this review when i receive it update i received the product today it has worked for a couple of weeks and the only problem i have is that the plastic part that came with it has a bad smell the packaging was very very good and the packaging was very good the packaging is very good and its a good product i have a nice white case and its perfect the colors are very good and the colors are great it is well made and it works very well the only downside is that it doesnt fit my new usb 30 port on the bottom of the case it does fit my new usb 30 port on the bottom of the case but its a little\nScore: 0.5266 - Review: the company that supplied this used mbpr was extremely helpful it wasnt really a used machine as far as i can tell this came in the original box more on that later and shrunk wrapped when i placed the order it wasnt supposed to arrive for 45 days i contacted the seller and asked if they could please ship it quicker i also mentioned i would pay whatever the additional charge would be they replied quickly had it delivered in two days ny to nj and there was no additional charge i was thrilled that is until i saw the laptop box it was in bad shape not horrible but one of the corners and under the corner was severely damaged crinkled and partially crushed enough so that it caused some concern about the laptops possible condition when i opened it turns out the laptop was in flawless condition so no biggie the box is still useable although damaged for eventual resale im assuming the box was damaged before they sent it since the shipping box that contained the laptop and its box was in great condition hmmm anyway it was listed as used but there wasnt a scratch ding or dent of any kind bottom line i got a great machine with no damage for a great price with excellent customer service no complaints just wish the laptop box wasnt damaged thats the only reason i gave them 4 stars instead of 5 highly recommend great experience overall\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}